{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visual Designer - Scoring Pipeline\n",
    "\n",
    "In this exercise we will be building a pipeline in Azure Machine Learning using the [Visual Designer](https://docs.microsoft.com/azure/machine-learning/concept-designer). Traditionally the Visual Designer is used for training and deploying models. With this exercise we will be using Visual Designer to build a batch scoring pipeline for a registered model trained in the earlier Modules of the workshop. Specifically we will use the diabetes Logistic Regression model that was trained and registered earlier. Below you can see a final picture of the scoring pipeline that will be built in this exercise.\n",
    "\n",
    "The pipeline will use the output file from the <u>Visual Designer Data Prep Pipeline</u> exercise. It will use the diabetes.csv file in the <b>/1-bronze</b> folder, score the dataset against the diabetes ML model, and then load the resulting dataset to the <b>/2-silver</b> folder in the data lake.\n",
    "\n",
    "![Picture of final scoring pipeline](./img/vdscorefinal.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Create new pipeline\n",
    "In this step we will create the new pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the Azure ML studio, navigate to <b>Designer</b> and press the <b>+</b> button under <b>New pipeline</b>\n",
    "\n",
    "![Screenshot of AML Studio highlighting the steps described to create a new pipeline](./img/vdnewpipeline.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. In <b>Settings</b> change the compute type to <b>Compute cluster</b> and select the appropriate compute cluster.\n",
    "1. Name the pipeline in the <b>Draft name</b> field using the convention \"pipeline-score-diabetes-\\<userid\\>-prod\"\n",
    "\n",
    "![Settings pane with compute settings and draft name fields highlighted](./img/vdnewpipelinescore.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Open <b>Data Input and Output</b> from the components menu.\n",
    "2. Drag <b>Import Data</b> onto the canvas.\n",
    "3. Change the <b>Data source</b> to <b>Datastore</b>\n",
    "1. Select the \\<workshop-datastore\\> \n",
    "1. Enter the storage path to the <b>diabetes.csv</b> file in the <b>/1-bronze</b> folder of the data lake.\n",
    "1. Validate by pressing <b>Preview schema</b>\n",
    "\n",
    "![Import Data component settings](./img/vdimportbronzescore.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Open <b>Python Language</b> from the components menu.\n",
    "1. Drag <b>Execute Python Script</b> onto the canvas.\n",
    "1. Connect <b>Import Data</b> with the <b>Dataset1: DataFrameDirectory</b> input.\n",
    "1. Copy past the following code in the <b>Python script</b> window. Replace \\<userid\\> in <b>Model.get_model_path()</b> with your userid.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from azureml.core import Model\n",
    "from azureml.core import Workspace\n",
    "import joblib\n",
    "\n",
    "# The entry point function MUST have two input arguments.\n",
    "# If the input port is not connected, the corresponding\n",
    "# dataframe argument will be None.\n",
    "#   Param<dataframe1>: a pandas.DataFrame\n",
    "#   Param<dataframe2>: a pandas.DataFrame\n",
    "def azureml_main(dataframe1 = None, dataframe2 = None):\n",
    "\n",
    "    model_path = Model.get_model_path('diabetes_model_<userid>')\n",
    "    model = joblib.load(model_path)\n",
    "\n",
    "    x = dataframe1[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree','Age']].values\n",
    "\n",
    "    yhat = model.predict(x)\n",
    "\n",
    "    dataframe1['Diabetes'] = yhat\n",
    "\n",
    "    return dataframe1\n",
    "```\n",
    "![Execute Python Script component settings](./img/vdpythonscriptscore.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Open <b>Data Input and Output</b> from the components menu.\n",
    "1. Drag <b>Export Data</b> onto the canvas.\n",
    "1. Connect <b>Execute Python Script</b> output <b>Result dataset: DataFrameDirectory</b> with the <b>Export Data</b> input.\n",
    "1. Select \\<workshop\\> datastore and use the following path for the exported file. \"/2-silver/diabetes/\\<userid\\>/diabetes.csv\"\n",
    "1. Select <b>csv</b> for the <b>File format</b>.\n",
    "\n",
    "![Export Data component settings](./img/vdexportscores.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Submit and Publish pipeline\n",
    "First submit the pipeline and ensure it runs as expected. Second publish the pipeline endpoint."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Press <b>Submit</b>\n",
    "2. Choose <b>Create New</b> for Experiment.\n",
    "3. Name the new experiment using this convention. \"pipeline-score-diabetes-\\<userid\\>-prod\"\n",
    "4. Press the <b>Submit</b> button.\n",
    "5. Monitor the run for completion.\n",
    "\n",
    "![Set up pipeline run settings](./img/vdsubmitscore.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Verify <b>diabetes.csv</b> was created after the pipeline run in <b>/2-silver</b> folder.\n",
    "\n",
    "![screenshot of Storage Explorer showing output files from pipeline run](./img/vdstorageexplorerscoredata.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Preview the diabetes.csv file and verify the <b>Diabetes</b> column is present with scores.\n",
    "\n",
    "![Preview of diabetes.csv score file with Diabetes column highlighted](./img/vdscoredatapreview.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Open the pipeline and press the <b>Publish</b> button.\n",
    "2. Choose <b>Create new</b> and name the pipeline endpoint the same as the pipeline draft.\n",
    "3. Press the <b>Publish</b> button.\n",
    "\n",
    "![The Set up published pipeline menu in the AML Studio Visual Designer](./img/vdpublishscorepipeline.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The End\n",
    "\n",
    "This score pipeline will be orchestrated using Azure Data Factory with data prep and training pipelines that are published in Module 3. "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a4c6afd7f173e0e931b0843fe6a0c2993fb0269572e807aff8dc4b63e60c94bb"
  },
  "kernelspec": {
   "display_name": "Python 3.7.3 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
